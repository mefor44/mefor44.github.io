{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I want to describe how **Product Quantisation method work**. The idea goal of this method is to efficiently represent massive number of `float` type vectors. The basic setup is as follows:\n",
    "* $N$ - number of vectors (embeddings)\n",
    "* $d$ - dimension of each vector\n",
    "* vectors contain `float32` \n",
    "\n",
    "Some hyperparameters:\n",
    "* $m$ - number of *segments* (in how many chunks we want to split our vectors)\n",
    "* $k$ - how many different codes do we want to have (often the power of $2$)\n",
    "\n",
    "Product Quantization algorithm:\n",
    "1. Split embeddings into $m$ segments\n",
    "1. For each segment run `Kmeans` with $k$ clusters and associate each cluster with its centroid\n",
    "1. Each cluster gets an integer: $0,...,k-1$\n",
    "1. This way we obtain $m$ sets of $k$ vectors with dimension $\\frac{d}{m}$\n",
    "\n",
    "How to represnt certain vector?\n",
    "1. For each segment find its cluster assignment in respective Kmean algorithm \n",
    "1. Represent that segment with integer assigned to that particular cluster\n",
    "1. Final vector is represented as an array of $\\frac{d}{m}$ integers (called $\\underline{code}$)\n",
    "\n",
    "**Warning!**\n",
    "It might happen that 2 different vectors (embeddings) receive the same code, thus get the same representation!!! This method <u>is not a lossless compression</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%hide\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
