{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh7LaSzfwcj2",
        "outputId": "08573a01-e064-4c84-8624-440ffb2a2d6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsWUrVh7vZtM",
        "outputId": "2dbdb078-f500-48f2-9bf2-e5c0b0faa0a5"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "#!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "#!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vit8xKCiXAue"
      },
      "source": [
        "# Link Prediction on MovieLens\n",
        "\n",
        "This colab notebook shows how to load a set of `*.csv` files as input and construct a heterogeneous graph from it.\n",
        "We will then use this dataset as input into a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial), and use it for the task of link prediction.\n",
        "A few code cells require user input to let the code run through successfully.\n",
        "If you are stuck on cells that require input, take a look at the fully filled out tutorial [here](https://medium.com/@pytorch_geometric/link-prediction-on-heterogeneous-graphs-with-pyg-6d5c29677c70).\n",
        "\n",
        "We are going to use the [MovieLens dataset](https://grouplens.org/datasets/movielens/) collected by the GroupLens research group.\n",
        "This toy dataset describes ratings and tagging activity from MovieLens.\n",
        "The dataset contains approximately 100k ratings across more than 9k movies from more than 600 users.\n",
        "We are going to use this dataset to generate two node types holding data for movies and users, respectively, and one edge type connecting users and movies, representing the relation of whether a user has rated a specific movie.\n",
        "\n",
        "The link prediction task then tries to predict missing ratings, and can, for example, be used to recommend users new movies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_pshZh8Y3dw"
      },
      "source": [
        "## Heterogeneous Graph Creation\n",
        "\n",
        "First, we download the dataset to an arbitrary folder (in this case, the current directory):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciYr7NWEv5_o",
        "outputId": "5bbe4a86-5d5b-4e42-d876-c7b58d8e030b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using existing file ml-latest-small.zip\n",
            "Extracting .\\ml-latest-small.zip\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import download_url, extract_zip\n",
        "\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movies_path = './ml-latest-small/movies.csv'\n",
        "ratings_path = './ml-latest-small/ratings.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B89RD_evY7uu"
      },
      "source": [
        "Before we create the heterogeneous graph, let’s take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6ixkcCOwCDi",
        "outputId": "4bc902aa-4707-48ef-c5f0-65a8d0f0faf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "movies.csv:\n",
            "===========\n",
            "   movieId                                       genres\n",
            "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
            "1        2                   Adventure|Children|Fantasy\n",
            "2        3                               Comedy|Romance\n",
            "3        4                         Comedy|Drama|Romance\n",
            "4        5                                       Comedy\n",
            "\n",
            "ratings.csv:\n",
            "============\n",
            "   userId  movieId\n",
            "0       1        1\n",
            "1       1        3\n",
            "2       1        6\n",
            "3       1       47\n",
            "4       1       50\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('movies.csv:')\n",
        "print('===========')\n",
        "print(pd.read_csv(movies_path)[[\"movieId\", \"genres\"]].head())\n",
        "print()\n",
        "print('ratings.csv:')\n",
        "print('============')\n",
        "print(pd.read_csv(ratings_path)[[\"userId\", \"movieId\"]].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgXipuWTZK39"
      },
      "source": [
        "We see that the `movies.csv` file provides two useful columns: `movieId` assigns a unique identifier to each movie, while the `genres` column represent genres of the given movie.\n",
        "We can make use of this column to define a feature representation that can be easily interpreted by machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd_BJMNcwJ7k",
        "outputId": "d9c2d6b4-d968-4226-e2d6-b643683931f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Action  Adventure  Drama  Horror\n",
            "movieId                                  \n",
            "1             0          1      0       0\n",
            "2             0          1      0       0\n",
            "3             0          0      0       0\n",
            "4             0          0      1       0\n",
            "5             0          0      0       0\n"
          ]
        }
      ],
      "source": [
        "# Load the entire movie data frame into memory:\n",
        "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
        "\n",
        "# Split genres and convert into indicator variables:\n",
        "genres = movies_df['genres'].str.get_dummies('|')\n",
        "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
        "\n",
        "# Use genres as movie input features:\n",
        "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
        "assert movie_feat.size() == (9742, 20)  # 20 genres in total."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kav2TaOSnK4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLaDBVP4plsS"
      },
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`).\n",
        "Due to simplicity, we do not make use of the additional `timestamp` and `rating` information.\n",
        "Here, we first read the `*.csv` file from disk, and create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`.\n",
        "This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a movie in the first row should be accessible via `x[0]`.\n",
        "\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGYv83WzSRr",
        "outputId": "35e859ca-75cb-407e-9a7c-b0d4b7b76fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   userId  mappedID\n",
            "0       1         0\n",
            "1       2         1\n",
            "2       3         2\n",
            "3       4         3\n",
            "4       5         4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   movieId  mappedID\n",
            "0        1         0\n",
            "1        2         1\n",
            "2        3         2\n",
            "3        4         3\n",
            "4        5         4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "=================================================\n",
            "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
            "        [   0,    2,    5,  ..., 9462, 9463, 9503]])\n"
          ]
        }
      ],
      "source": [
        "# Load the entire ratings data frame into memory:\n",
        "ratings_df = pd.read_csv(ratings_path)\n",
        "\n",
        "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
        "unique_user_id = ratings_df['userId'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userId': unique_user_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
        "})\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'movieId': movies_df.index,\n",
        "    'mappedID': pd.RangeIndex(len(movies_df)),\n",
        "})\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "\n",
        "# Perform merge to obtain the edges from users and movies:\n",
        "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
        "                            left_on='userId', right_on='userId', how='left')\n",
        "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
        "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
        "                            left_on='movieId', right_on='movieId', how='left')\n",
        "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
        "\n",
        "# With this, we are ready to construct our `edge_index` in COO format\n",
        "# following PyG semantics:\n",
        "edge_index_user_to_movie = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
        "assert edge_index_user_to_movie.size() == (2, 100836)\n",
        "\n",
        "print()\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"=================================================\")\n",
        "print(edge_index_user_to_movie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w9fCnjvqmd2"
      },
      "source": [
        "With this, we are ready to initialize our `HeteroData` object and pass the necessary information to it.\n",
        "Note that we also pass in a `node_id` vector to each node type in order to reconstruct the original node indices from sampled subgraphs.\n",
        "We also take care of adding reverse edges to the `HeteroData` object.\n",
        "This allows our GNN model to use both directions of the edge for message passing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_63--974srt",
        "outputId": "32fe707d-f9ac-4dca-8c7b-52bbb8ddfa07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HeteroData(\n",
            "  user={ node_id=[610] },\n",
            "  movie={\n",
            "    node_id=[9742],\n",
            "    x=[9742, 20],\n",
            "  },\n",
            "  (user, rates, movie)={ edge_index=[2, 100836] },\n",
            "  (movie, rev_rates, user)={ edge_index=[2, 100836] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "data = HeteroData()\n",
        "\n",
        "# Save node indices:\n",
        "data[\"user\"].node_id = torch.arange(len(unique_user_id))\n",
        "data[\"movie\"].node_id = torch.arange(len(movies_df))\n",
        "\n",
        "# Add the node features and edge indices:\n",
        "data[\"movie\"].x = movie_feat  # TODO\n",
        "data[\"user\", \"rates\", \"movie\"].edge_index = edge_index_user_to_movie  # TODO\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "\n",
        "# TODO:\n",
        "data = T.ToUndirected()(data)\n",
        "print(data)\n",
        "\n",
        "assert data.node_types == [\"user\", \"movie\"]\n",
        "assert data.edge_types == [(\"user\", \"rates\", \"movie\"),\n",
        "                           (\"movie\", \"rev_rates\", \"user\")]\n",
        "assert data[\"user\"].num_nodes == 610\n",
        "assert data[\"user\"].num_features == 0\n",
        "assert data[\"movie\"].num_nodes == 9742\n",
        "assert data[\"movie\"].num_features == 20\n",
        "assert data[\"user\", \"rates\", \"movie\"].num_edges == 100836\n",
        "assert data[\"movie\", \"rev_rates\", \"user\"].num_edges == 100836"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QGdkLAurBq9"
      },
      "source": [
        "## Defining Edge-level Training Splits\n",
        "\n",
        "Since our data is now ready-to-be-used, we can split the ratings of users into training, validation, and test splits.\n",
        "This is needed in order to ensure that we leak no information about edges used during evaluation into the training phase.\n",
        "For this, we make use of the [`transforms.RandomLinkSplit`](https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.RandomLinkSplit) transformation from PyG.\n",
        "This transforms randomly divides the edges in the `(\"user\", \"rates\", \"movie\")` into training, validation and test edges.\n",
        "The `disjoint_train_ratio` parameter further separates edges in the training split into edges used for message passing (`edge_index`) and edges used for supervision (`edge_label_index`).\n",
        "Note that we also need to specify the reverse edge type `(\"movie\", \"rev_rates\", \"user\")`.\n",
        "This allows the `RandomLinkSplit` transform to drop reverse edges accordingly to not leak any information into the training phase.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "This is so called <b>Transductive split</b>. In case of link prediction task we follow procedure described below:\n",
        "1. At training time: we use <b>training message edges</b> to predict <b>training supervision edges</b>,\n",
        "1. At validation time: we use <b>training message edges</b> & <b>training supervision edges</b> to predict <b>validation edges</b>,\n",
        "1. At test time: we use <b>training message edges</b> & <b>training supervision edges</b> & <b>validation edges</b> to predict <b>test edges</b>.\n",
        "</div>\n",
        "\n",
        "We can think about it as dividing our set into 4 parts.\n",
        "In **Hetero Data** object, under `(\"user\", \"rates\", \"movie\")`, we have three important values. They are described below:\n",
        "* `edge_index` is a torch object with dimensions $[2, n_1]$, in which we store edges (as adjacency list). This edges are later on used for message passing.\n",
        "* `edge_label_index` is a torch object with dimensions $[2, n_2]$, in which we store edges (as adjacency list). This adges are later on used as supervision (we have labels assosiated with them).\n",
        "* `edge_label` - is a torch object with dimension $[n_2]$, in which we store the labels of each node from `edge_label_index`\n",
        "If we want to, we can either make `edge_index` = `edge_label_index` or we can do a proper Transductie Split. In latter case we divide all edges into disjoint sets. One for message passing, and one for supervision. Is that case $n_1 + n_2 = n$ (where $n$ is total number of edges).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rwgNwoa26Eja"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data:\n",
            "==============\n",
            "HeteroData(\n",
            "  user={ node_id=[610] },\n",
            "  movie={\n",
            "    node_id=[9742],\n",
            "    x=[9742, 20],\n",
            "  },\n",
            "  (user, rates, movie)={\n",
            "    edge_index=[2, 56469],\n",
            "    edge_label=[24201],\n",
            "    edge_label_index=[2, 24201],\n",
            "  },\n",
            "  (movie, rev_rates, user)={ edge_index=[2, 56469] }\n",
            ")\n",
            "\n",
            "Validation data:\n",
            "================\n",
            "HeteroData(\n",
            "  user={ node_id=[610] },\n",
            "  movie={\n",
            "    node_id=[9742],\n",
            "    x=[9742, 20],\n",
            "  },\n",
            "  (user, rates, movie)={\n",
            "    edge_index=[2, 80670],\n",
            "    edge_label=[30249],\n",
            "    edge_label_index=[2, 30249],\n",
            "  },\n",
            "  (movie, rev_rates, user)={ edge_index=[2, 80670] }\n",
            ")\n",
            "56469\n"
          ]
        }
      ],
      "source": [
        "# For this, we first split the set of edges into\n",
        "# training (80%), validation (10%), and testing edges (10%).\n",
        "# Across the training edges, we use 70% of edges for message passing,\n",
        "# and 30% of edges for supervision.\n",
        "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1.\n",
        "# Negative edges during training will be generated on-the-fly, so we don't want to\n",
        "# add them to the graph right away.\n",
        "# Overall, we can leverage the `RandomLinkSplit()` transform for this from PyG:\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1,  # TODO\n",
        "    num_test=.1,  # TODO\n",
        "    disjoint_train_ratio=0.3,  # TODO\n",
        "    neg_sampling_ratio=2,  # TODO\n",
        "    add_negative_train_samples=False,  # TODO\n",
        "    edge_types=(\"user\", \"rates\", \"movie\"),\n",
        "    rev_edge_types=(\"movie\", \"rev_rates\", \"user\"),\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data)\n",
        "print(\"Training data:\")\n",
        "print(\"==============\")\n",
        "print(train_data)\n",
        "print()\n",
        "print(\"Validation data:\")\n",
        "print(\"================\")\n",
        "print(val_data)\n",
        "print(train_data[\"user\", \"rates\", \"movie\"].num_edges)\n",
        "assert train_data[\"user\", \"rates\", \"movie\"].num_edges == 56469\n",
        "assert train_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 24201\n",
        "assert train_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 56469\n",
        "# No negative edges added:\n",
        "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 1\n",
        "assert train_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1\n",
        "\n",
        "assert val_data[\"user\", \"rates\", \"movie\"].num_edges == 80670\n",
        "assert val_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 30249\n",
        "assert val_data[\"movie\", \"rev_rates\", \"user\"].num_edges == 80670\n",
        "# Negative edges with ratio 2:1:\n",
        "assert val_data[\"user\", \"rates\", \"movie\"].edge_label.long().bincount().tolist() == [20166, 10083]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([24201])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[\"user\", \"rates\", \"movie\"].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={ node_id=[610] },\n",
              "  movie={\n",
              "    node_id=[9742],\n",
              "    x=[9742, 20],\n",
              "  },\n",
              "  (user, rates, movie)={\n",
              "    edge_index=[2, 80670],\n",
              "    edge_label=[30249],\n",
              "    edge_label_index=[2, 30249],\n",
              "  },\n",
              "  (movie, rev_rates, user)={ edge_index=[2, 80670] }\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.3333)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(train_data[\"user\", \"rates\", \"movie\"].edge_label.mean())\n",
        "val_data[\"user\", \"rates\", \"movie\"].edge_label.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKLwq6RsYoh"
      },
      "source": [
        "## Defining Mini-batch Loaders\n",
        "\n",
        "We are now ready to create a mini-batch loader that will generate subgraphs that can be used as input into our GNN.\n",
        "While this step is not strictly necessary for small-scale graphs, it is absolutely necessary to apply GNNs on larger graphs that do not fit onto GPU memory otherwise.\n",
        "Here, we make use of the [`loader.LinkNeighborLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.LinkNeighborLoader) which samples multiple hops from both ends of a link and creates a subgraph from it.\n",
        "Here, `edge_label_index` serves as the \"seed links\" to start sampling from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24201"
            ]
          },
          "execution_count": 145,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(edge_label_index[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogh615ka9I2c",
        "outputId": "e4b6d4d3-f59b-4f8a-9b78-a2536ed08516"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\marzecm\\anaconda3\\envs\\lightgcn\\lib\\site-packages\\torch_geometric\\data\\storage.py:318: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set 'set()'. Please explicitly set 'num_nodes' as an attribute of 'data[edge_index]' to suppress this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[418],\n",
            "    n_id=[418],\n",
            "  },\n",
            "  movie={\n",
            "    node_id=[965],\n",
            "    x=[965, 20],\n",
            "    n_id=[965],\n",
            "  },\n",
            "  edge_index={ n_id=[0] },\n",
            "  (user, rates, movie)={\n",
            "    edge_index=[2, 1348],\n",
            "    edge_label=[3],\n",
            "    edge_label_index=[2, 3],\n",
            "    e_id=[1348],\n",
            "    input_id=[1],\n",
            "  },\n",
            "  (movie, rev_rates, user)={\n",
            "    edge_index=[2, 1625],\n",
            "    e_id=[1625],\n",
            "  }\n",
            ")\n",
            "{'edge_index': tensor([[  3,   4,   5,  ...,  43,   0, 221],\n",
            "        [  0,   0,   0,  ..., 228, 228, 228]]), 'edge_label': tensor([1., 0., 0.]), 'edge_label_index': tensor([[0, 1, 2],\n",
            "        [0, 2, 1]]), 'e_id': tensor([35629, 50558, 41020,  ..., 27717, 35015, 10614]), 'input_id': tensor([18243])}\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# In the first hop, we sample at most 20 neighbors.\n",
        "# In the second hop, we sample at most 10 neighbors.\n",
        "# In addition, during training, we want to sample negative edges on-the-fly with\n",
        "# a ratio of 2:1.\n",
        "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.sampler import NegativeSampling\n",
        "\n",
        "# Define seed edges:\n",
        "edge_label_index = train_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "edge_label = train_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,  # TODO\n",
        "    num_neighbors=[20,10,5],  # TODO\n",
        "    neg_sampling_ratio=2,  # TODO\n",
        "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    # neg_sampling=NegativeSampling(mode=\"triplet\", amount=1)\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "print(sampled_data[(\"user\", \"rates\", \"movie\")])\n",
        "print(\"---\"*20)\n",
        "# print(sampled_data[\"user\"])\n",
        "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
        "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() == 0\n",
        "\n",
        "# assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() == 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "418"
            ]
          },
          "execution_count": 218,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sampled_data[\"user\"][\"node_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3693)"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_data[\"movie\"][\"node_id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1348"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sampled_data[\"user\", \"rates\", \"movie\"][\"e_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([], size=(2, 0), dtype=torch.int64)"
            ]
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_index = train_data[\"user\", \"rates\", \"movie\"].edge_index\n",
        "edge_index[:, (edge_index[0]==379) & (edge_index[1]==3693)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 379],\n",
              "        [3693]])"
            ]
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_label_index[:, (edge_label_index[0]==379) & (edge_label_index[1]==3693)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 379, 3693]), tensor([ 609, 3693]))"
            ]
          },
          "execution_count": 200,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_label_index[:,9011], edge_index[:,15939]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj7biOtatAmG"
      },
      "source": [
        "## Creating a Heterogeneous Link-level GNN\n",
        "\n",
        "We are now ready to create our heterogeneous GNN.\n",
        "The GNN is responsible for learning enriched node representations from the surrounding subgraphs, which can be then used to derive edge-level predictions.\n",
        "For defining our heterogenous GNN, we make use of [`nn.SAGEConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv) and the [`nn.to_hetero()`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.to_hetero_transformer.to_hetero) function, which transforms a GNN defined on homogeneous graphs to be applied on heterogeneous ones.\n",
        "\n",
        "In addition, we define a final link-level classifier, which simply takes both node embeddings of the link we are trying to predict, and applies a dot-product on them.\n",
        "\n",
        "As users do not have any node-level information, we choose to learn their features jointly via a `torch.nn.Embedding` layer. In order to improve the expressiveness of movie features, we do the same for movie nodes, and simply add their shallow embeddings to the pre-defined genre features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebsFf-Pr_4LF",
        "outputId": "5756285f-592d-4783-a31d-1bbccf8fd454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (movie_lin): Linear(in_features=20, out_features=64, bias=True)\n",
            "  (user_emb): Embedding(610, 64)\n",
            "  (movie_emb): Embedding(9742, 64)\n",
            "  (gnn): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__rates__movie): SAGEConv(64, 64, aggr=mean)\n",
            "      (movie__rev_rates__user): SAGEConv(64, 64, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Classifier()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        # Define a 2-layer GNN computation graph.\n",
        "        # Use a *single* `ReLU` non-linearity in-between.\n",
        "        # TODO:\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
        "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
        "          \"movie\": self.movie_lin(data[\"movie\"].x) + self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"movie\"],\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05dfew-WuWHN"
      },
      "source": [
        "## Training a Heterogeneous Link-level GNN\n",
        "\n",
        "Training our GNN is then similar to training any PyTorch model.\n",
        "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
        "\n",
        "The training loop then iterates over our mini-batches, applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions (here we make use of binary cross entropy), and adjusts model parameters via back-propagation and stochastic gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqLuXEcrAMru",
        "outputId": "65d515e9-00d6-48d9-92f2-2b41207e6d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: 'cpu'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:22<00:00,  8.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 0.3531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:25<00:00,  7.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 002, Loss: 0.3324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:18<00:00, 10.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 003, Loss: 0.3154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:20<00:00,  9.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 004, Loss: 0.3028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 190/190 [00:21<00:00,  8.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 005, Loss: 0.2922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(type(sampled_data))\n",
        "        # print(sampled_data)\n",
        "        # break\n",
        "        # print(sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"])\n",
        "        # print(len(sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"]))\n",
        "\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        pred = model(sampled_data)\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"])\n",
        "        # raise NotImplementedError\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq-I2xaYueF0"
      },
      "source": [
        "## Evaluating a Heterogeneous Link-level GNN\n",
        "\n",
        "After training, we evaluate our model on useen data coming from the validation set.\n",
        "For this, we define a new `LinkNeighborLoader` (which now iterates over the edges in the validation set), obtain the predictions on validation edges by running the model, and finally evaluate the performance of the model by computing the AUC score over the set of predictions and their corresponding ground-truth edges (including both positive and negative edges)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIrRn9YoNllj",
        "outputId": "174894fc-fc38-4500-a022-f8232c5015b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  user={\n",
            "    node_id=[608],\n",
            "    n_id=[608],\n",
            "  },\n",
            "  movie={\n",
            "    node_id=[2713],\n",
            "    x=[2713, 20],\n",
            "    n_id=[2713],\n",
            "  },\n",
            "  (user, rates, movie)={\n",
            "    edge_index=[2, 21279],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[21279],\n",
            "    input_id=[384],\n",
            "  },\n",
            "  (movie, rev_rates, user)={\n",
            "    edge_index=[2, 7937],\n",
            "    e_id=[7937],\n",
            "  }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[20, 10, 5],\n",
        "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() >= 0\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() <= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi25Z7lFPPjc",
        "outputId": "9cdf67ca-f335-4009-b2df-769697f1c99a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:06<00:00, 11.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation AUC: 0.9290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        pred = model(sampled_data)\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"])\n",
        "        # raise NotImplementedError\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LightGcn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Node layers__user__rates__movie target layers.user__rates__movie references nonexistent attribute user__rates__movie of layers",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32md:\\MM\\mefor44.github.io\\notebooks\\9_Link_Prediction_on_MovieLens.ipynb Cell 37\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m             x_dict[\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m             x_dict[\u001b[39m\"\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m             data[\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrates\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmovie\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39medge_label_index,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m pred\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model \u001b[39m=\u001b[39m Model(hidden_channels\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n",
            "\u001b[1;32md:\\MM\\mefor44.github.io\\notebooks\\9_Link_Prediction_on_MovieLens.ipynb Cell 37\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgnn \u001b[39m=\u001b[39m LightGCNBase(num_layers\u001b[39m=\u001b[39mnum_layers)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Convert GNN model into a heterogeneous variant:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgnn \u001b[39m=\u001b[39m to_hetero(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgnn, metadata\u001b[39m=\u001b[39;49mdata\u001b[39m.\u001b[39;49mmetadata())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/MM/mefor44.github.io/notebooks/9_Link_Prediction_on_MovieLens.ipynb#X62sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m Classifier()\n",
            "File \u001b[1;32mc:\\Users\\marzecm\\anaconda3\\envs\\lightgcn\\lib\\site-packages\\torch_geometric\\nn\\to_hetero_transformer.py:120\u001b[0m, in \u001b[0;36mto_hetero\u001b[1;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhich node representations are learned for each node type in\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m        transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m transformer \u001b[39m=\u001b[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001b[1;32m--> 120\u001b[0m \u001b[39mreturn\u001b[39;00m transformer\u001b[39m.\u001b[39;49mtransform()\n",
            "File \u001b[1;32mc:\\Users\\marzecm\\anaconda3\\envs\\lightgcn\\lib\\site-packages\\torch_geometric\\nn\\fx.py:191\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m     code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mpython_code(\u001b[39m'\u001b[39m\u001b[39mself\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    189\u001b[0m     \u001b[39mprint\u001b[39m(code\u001b[39m.\u001b[39msrc \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(code, \u001b[39m'\u001b[39m\u001b[39msrc\u001b[39m\u001b[39m'\u001b[39m) \u001b[39melse\u001b[39;00m code)\n\u001b[1;32m--> 191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgm\u001b[39m.\u001b[39;49mgraph\u001b[39m.\u001b[39;49mlint()\n\u001b[0;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm\u001b[39m.\u001b[39mrecompile()\n\u001b[0;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgm\n",
            "File \u001b[1;32mc:\\Users\\marzecm\\anaconda3\\envs\\lightgcn\\lib\\site-packages\\torch\\fx\\graph.py:1360\u001b[0m, in \u001b[0;36mGraph.lint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1358\u001b[0m seen_qualname \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(target_atoms[:i])\n\u001b[0;32m   1359\u001b[0m \u001b[39mif\u001b[39;00m new_m_itr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1360\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNode \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m}\u001b[39;00m\u001b[39m target \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m.\u001b[39mtarget\u001b[39m}\u001b[39;00m\u001b[39m references nonexistent attribute \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1361\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00matom\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mseen_qualname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1362\u001b[0m \u001b[39mif\u001b[39;00m (node\u001b[39m.\u001b[39mop \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcall_module\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1363\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(new_m_itr, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)):\n\u001b[0;32m   1364\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNode \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m}\u001b[39;00m\u001b[39m target \u001b[39m\u001b[39m{\u001b[39;00mnode\u001b[39m.\u001b[39mtarget\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00matom\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mseen_qualname\u001b[39m}\u001b[39;00m\u001b[39m does \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1365\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mnot reference an nn.Module\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Node layers__user__rates__movie target layers.user__rates__movie references nonexistent attribute user__rates__movie of layers"
          ]
        }
      ],
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero, LGConv\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LightGCNBase(torch.nn.Module):\n",
        "    def __init__(self, num_layers=3):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.layers.append(LGConv(normalize=True))\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor) -> Tensor:\n",
        "        return self.layers(x, edge_index)\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels=64, num_layers=3):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "        self.user_emb = torch.nn.Embedding(data[\"user\"].num_nodes, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(data[\"movie\"].num_nodes, hidden_channels)\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = LightGCNBase(num_layers=num_layers)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> Tensor:\n",
        "        x_dict = {\n",
        "          \"user\": self.user_emb(data[\"user\"].node_id),\n",
        "          \"movie\": self.movie_emb(data[\"movie\"].node_id),\n",
        "        }\n",
        "\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "\n",
        "        pred = self.classifier(\n",
        "            x_dict[\"user\"],\n",
        "            x_dict[\"movie\"],\n",
        "            data[\"user\", \"rates\", \"movie\"].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "\n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.models import LightGCN\n",
        "from torch_geometric.nn import LGConv\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "# lightgcn = LightGCN(\n",
        "#     num_nodes=train_data[\"user\"].num_nodes + train_data[\"item\"].num_nodes,\n",
        "#     embedding_dim=64,\n",
        "#     num_layers=3\n",
        "# )\n",
        "\n",
        "lightgcn = lightgcn.to(device)\n",
        "optimizer = torch.optim.Adam(lightgcn.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        # print(type(sampled_data))\n",
        "        # print(sampled_data)\n",
        "        # print(sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"])\n",
        "        # print(len(sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"]))\n",
        "\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        sampled_edge_index = sampled_data[\"user\", \"rates\", \"movie\"][\"edge_index\"]\n",
        "        sampled_edge_label_index = dupa\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        pred = lightgcn(sampled_data)\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, sampled_data[\"user\", \"rates\", \"movie\"][\"edge_label\"])\n",
        "        # raise NotImplementedError\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO:\n",
        "- play a bit with hyperparameters (especially number of gnn layers)\n",
        "- implement and test LighGCN model\n",
        "- compare the results with [pyotrch geometric implementation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.models.LightGCN.html#torch_geometric.nn.models.LightGCN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
